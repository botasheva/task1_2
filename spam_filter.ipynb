{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "import json\n",
      "import random\n",
      "import os \n",
      "import shutil \n",
      "from collections import defaultdict, OrderedDict, Counter\n",
      "import heapq\n",
      " \n",
      "def utf_open(open_type, *parts):\n",
      "    return codecs.open(os.path.join(*parts), open_type, 'utf8')\n",
      " \n",
      "def list_files(dir_name):\n",
      "    return sorted([f for f in os.listdir(dir_name) \n",
      "                    if os.path.isfile(os.path.join(dir_name, f))]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split():\n",
      "    stats = {'train': 0,\n",
      "             'cv': 0,\n",
      "             'test': 0}\n",
      "    dir_name = \"spam_data/train\"\n",
      "    for d in [\"train\", \"cv\", \"test\"]:\n",
      "        full_d = os.path.join(dir_name, d)\n",
      "        if not os.path.exists(full_d):\n",
      "            os.mkdir(full_d)\n",
      "    for file_name in os.listdir(dir_name):\n",
      "        if not os.path.isfile(os.path.join(dir_name, file_name)):\n",
      "            continue\n",
      "        r = random.random()\n",
      "        if r < 0.7:\n",
      "            file_type = 'train'\n",
      "        elif r < 0.85:\n",
      "            file_type = 'cv'\n",
      "        else:\n",
      "            file_type = 'test'\n",
      "        stats[file_type] += 1\n",
      "        shutil.copyfile(os.path.join(dir_name, file_name),\n",
      "                        os.path.join(dir_name, file_type, file_name))\n",
      "    print stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(word):\n",
      "    return word.strip(\" \\n!@.-\\\"'$?()[]<>,*/\\\\+&:~_`{}^\").lower()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def text_to_vector(full_dict, text):\n",
      "    vec = [0] * len(full_dict)\n",
      "    for word in text.split():\n",
      "        normalized_word = normalize(word)\n",
      "        if normalized_word and normalized_word in full_dict:\n",
      "            vec[full_dict[normalized_word]] = 1\n",
      "    return vec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dist(vec1, vec2):\n",
      "    acc = 0\n",
      "    for i in xrange(len(vec1)):\n",
      "        acc += vec1[i] * vec2[i]\n",
      "    return float(acc) / ((abs(sum(vec1)) ** 0.5) * (abs(sum(vec2)) ** 0.5) + 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify(learned_data, mail, k):\n",
      "    vec = text_to_vector(learned_data['full_dict'],\n",
      "                          mail['body'])\n",
      "    distances = ({'dist': dist(vec, known_vec['vec']),\n",
      "                  'is_spam': known_vec['is_spam']}\n",
      "                    for known_vec in learned_data['vectors'])\n",
      "    c = Counter(x['is_spam'] for x in heapq.nlargest(k, distances, lambda x: x['dist']))\n",
      "    return c[True] > c[False]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def learn(word_threshold):\n",
      "    dir_name = \"spam_data/train/\"\n",
      "    freqs = {}\n",
      "    full_dict = {}\n",
      "    idx = 0\n",
      "# word_threshold = 5\n",
      "    for file_name in list_files(dir_name):\n",
      "        with utf_open('r', dir_name, file_name) as f:\n",
      "            data = json.load(f)\n",
      "        for word in data['body'].split():\n",
      "            normalized_word = normalize(word)\n",
      "            if normalized_word:\n",
      "                if normalized_word not in freqs:\n",
      "                    freqs[normalized_word] = 1\n",
      "                else:\n",
      "                    freqs[normalized_word] += 1\n",
      "                    if freqs[normalized_word] == word_threshold:\n",
      "                        full_dict[normalized_word] = idx\n",
      "                        idx += 1\n",
      "    vectors = []\n",
      "    for file_name in list_files(dir_name):\n",
      "        with utf_open('r', dir_name, file_name) as f:\n",
      "            data = json.load(f)\n",
      "        vec = text_to_vector(full_dict, data['body'])\n",
      "        vectors.append({'vec': vec,\n",
      "                        'is_spam': data['is_spam']})\n",
      "    return {'full_dict': full_dict,\n",
      "            'vectors': vectors}\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test():\n",
      "    dir_name = \"spam_data/train/cv\"\n",
      "    for threshold in [4]:\n",
      "        learned_data = learn(threshold)\n",
      "        print \"learned\", len(learned_data['vectors'][0]['vec']), \"words, threshold\", threshold\n",
      "        for k in [3]:\n",
      "            stats = {'fp': 0, 'tp': 0, 'fn': 0, 'tn': 0}\n",
      "            for file_name in list_files(dir_name):\n",
      "                with utf_open('r', dir_name, file_name) as f:\n",
      "                    data = json.load(f)\n",
      "                test_result = classify(learned_data, data, k)\n",
      "                true_result = data['is_spam']\n",
      "                if test_result and true_result:\n",
      "                    stats['tp'] += 1\n",
      "                if test_result and not true_result:\n",
      "                    stats['fp'] += 1\n",
      "                if not test_result and not true_result:\n",
      "                    stats['tn'] += 1\n",
      "                if not test_result and true_result:\n",
      "                    stats['fn'] += 1\n",
      "\n",
      "            accuracy = float(stats['tp'] + stats['tn']) / sum(stats.values())\n",
      "            precision = float(stats['tp']) / (stats['tp'] + stats['fp'])\n",
      "            recall = float(stats['tp']) / (stats['tp'] + stats['fn'])\n",
      "            f_score = 2 * precision * recall / (precision + recall) \n",
      "            print \"{0}\\t{1}\\t{2}\\t{3}\\t{4}\".format(k, accuracy, f_score, precision, recall)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gen_final():\n",
      "    learned_data = learn(4)\n",
      "    dir_name = \"spam_data/test/\"\n",
      "    print \"learned\", len(learned_data['vectors'][0]['vec']), \"words\"\n",
      "    with codecs.open('test.txt', 'w', 'utf-8') as out:\n",
      "        for file_name in os.listdir(dir_name):\n",
      "            mail = json.load(codecs.open(os.path.join(dir_name, file_name), 'r', 'utf-8'))\n",
      "            result = classify(learned_data, mail, 3)\n",
      "            out.write(u'%s\\t%s\\n' % (file_name, unicode(result)))\n",
      " \n",
      "if __name__ == '__main__':\n",
      "    gen_final() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}